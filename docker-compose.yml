services:
  questdb:
    image: questdb/questdb:8.1.1
    container_name: rta_questdb
    restart: always
    ports:
      - "8812:8812"
      - "9000:9000"
      - "9009:9009"
      - "9003:9003"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - QDB_METRICS_ENABLED=TRUE
      - QDB_LINE_TCP_WRITER_WORKER_COUNT=1
    volumes:
      - ./questdb/questdb_root:/var/lib/questdb/:rw

  grafana:
    image: grafana/grafana-oss:11.2.0
    container_name: rta_grafana
    restart: always
    user: "${DOCKER_COMPOSE_USER_ID:-}"
    ports:
      - 3000:3000
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./dashboard/grafana/home_dir/var_lib_grafana:/var/lib/grafana/:rw
      - ./dashboard/grafana/home_dir/etc_grafana:/etc/grafana/:rw
    environment:
      - GF_INSTALL_PLUGINS=questdb-questdb-datasource
      - QDB_CLIENT_HOST=${QDB_CLIENT_HOST:-host.docker.internal}
      - QDB_CLIENT_PORT=${QDB_CLIENT_PORT:-8812}
      - QDB_CLIENT_USER=${QDB_CLIENT_USER:-admin}
      - QDB_CLIENT_PASSWORD=${QDB_CLIENT_PASSWORD:-quest}
      # use the value "disable" for local installations, and "require" for QuestDB Cloud
      - QDB_SSL_MODE=${QDB_SSL_MODE:-disable}

  jupyter-notebook:
    image:    jupyter/scipy-notebook
    container_name: rta_jupyter
    volumes:
      - ./notebooks:/home/jovyan:rw
      - ./ingestion/python:/home/ingestion:rw
    ports:
      - 8888:8888
    command: sh -c "pip install questdb psycopg[binary] psycopg2-binary PyGithub kafka-python confluent-kafka \"confluent-kafka[avro]\" fastavro requests && start-notebook.sh --NotebookApp.password= --NotebookApp.token="
    depends_on:
      - questdb
      - broker
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - RESTARTABLE=yes
      - DOCKER_STACKS_JUPYTER_CMD=notebook
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
      - QUESTDB_HTTP_ENDPOINT=${QUESTDB_HTTP_ENDPOINT:-host.docker.internal:9000}
      - QDB_CLIENT_HOST=${QDB_CLIENT_HOST:-host.docker.internal}
      - QDB_CLIENT_PORT=${QDB_CLIENT_PORT:-8812}
      - QDB_CLIENT_USER=${QDB_CLIENT_USER:-admin}
      - QDB_CLIENT_PASSWORD=${QDB_CLIENT_PASSWORD:-quest}


  broker:
    image: confluentinc/cp-kafka:7.7.0
    hostname: broker
    container_name: rta_kafka_broker
    ports:
      - "9092:9092"
      - "9101:9101"
      - "8778:8778"   #Jolokia agent for MX monitoring metrics
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./monitoring/kafka-agent:/usr/jolokia/agents:ro   #Jolokia agent for MX monitoring metrics
    environment:
      KAFKA_OPTS: -javaagent:/usr/jolokia/agents/jolokia-jvm-1.7.2.jar=host=0.0.0.0    #Jolokia agent for MX monitoring metrics
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'QTkwRDkzMDg3QTdFNDJCRU'

  schema_registry:
    image: confluentinc/cp-schema-registry:7.7.0
    hostname: schema_registry
    container_name: rta_schema_registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema_registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,OPTIONS'

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.7.0
    hostname: kafka-connect
    container_name: rta_kafka_connect
    depends_on:
      - broker
    ports:
      - "8083:8083"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./kafka-connect-plugins:/etc/kafka-connect/jars # Mount local directory for plugins
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.5.3-0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/jars,/usr/share/confluent-hub-components"
      QUESTDB_HTTP_ENDPOINT: "${QUESTDB_HTTP_ENDPOINT:-host.docker.internal:9000}"
    command:
    - bash
    - -c
    - |
      # Launch Kafka Connect
      /etc/confluent/docker/run &
      #
      # Wait for Kafka Connect listener
      echo "Waiting for Kafka Connect to start listening on localhost â³"
      while : ; do
        curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
        echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
        if [ $$curl_status -eq 200 ] ; then
          break
        fi
        sleep 5
      done

      echo -e "\n--\n+> Registering QuestDB Connector"

      curl -s -X PUT -H  "Content-Type:application/json" http://localhost:8083/connectors/questdb-iot/config -d '{
      "connector.class": "io.questdb.kafka.QuestDBSinkConnector",
          "topics": "iot_data",
          "client.conf.string": "http::addr=${QUESTDB_HTTP_ENDPOINT:-host.docker.internal:9000};",
          "name": "questdb-iot",
          "value.converter": "org.apache.kafka.connect.json.JsonConverter",
          "include.key": false,
          "key.converter": "org.apache.kafka.connect.storage.StringConverter",
          "table": "iot_data",
          "symbols": "device_type",
          "value.converter.schemas.enable": false
      }'

      curl -s -X PUT -H  "Content-Type:application/json" http://localhost:8083/connectors/questdb-github/config -d '{
      "connector.class": "io.questdb.kafka.QuestDBSinkConnector",
          "topics": "github_events",
          "client.conf.string": "http::addr=${QUESTDB_HTTP_ENDPOINT:-host.docker.internal:9000};",
          "name": "questdb-github",
          "value.converter": "org.apache.kafka.connect.json.JsonConverter",
          "include.key": false,
          "key.converter": "org.apache.kafka.connect.storage.StringConverter",
          "table": "github_events",
          "symbols": "type,repo",
          "timestamp.field.name": "created_at",
          "value.converter.schemas.enable": false
      }'

      curl -s -X PUT -H  "Content-Type:application/json" http://localhost:8083/connectors/questdb-trades/config -d '{
      "connector.class": "io.questdb.kafka.QuestDBSinkConnector",
          "topics": "trades",
          "client.conf.string": "http::addr=${QUESTDB_HTTP_ENDPOINT:-host.docker.internal:9000};",
          "name": "questdb-trades",
          "value.converter": "io.confluent.connect.avro.AvroConverter",
          "value.converter.schema.registry.url": "http://schema_registry:8081",
          "include.key": false,
          "key.converter": "io.confluent.connect.avro.AvroConverter",
          "key.converter.schema.registry.url": "http://schema_registry:8081",
          "table": "trades",
          "symbols": "symbol, side",
          "timestamp.field.name": "timestamp",
          "value.converter.schemas.enable": true
      }'

      curl -s -X PUT -H  "Content-Type:application/json" http://localhost:8083/connectors/questdb-smart-meters/config -d '{
      "connector.class": "io.questdb.kafka.QuestDBSinkConnector",
          "topics": "smart-meters",
          "client.conf.string": "http::addr=${QUESTDB_HTTP_ENDPOINT:-host.docker.internal:9000};",
          "name": "questdb-smart-meters",
          "value.converter": "io.confluent.connect.avro.AvroConverter",
          "value.converter.schema.registry.url": "http://schema_registry:8081",
          "include.key": false,
          "key.converter": "io.confluent.connect.avro.AvroConverter",
          "key.converter.schema.registry.url": "http://schema_registry:8081",
          "table": "smart_meters",
          "symbols": "device_id, mark_model, status",
          "timestamp.field.name": "timestamp",
          "value.converter.schemas.enable": true
      }'

      sleep infinity

  telegraf:
    image: telegraf
    container_name: rta_telegraf
    depends_on:
      - questdb
      - broker
    volumes:
      - ./monitoring/telegraf/kafka_and_questdb_telegraf.conf:/etc/telegraf/telegraf.conf:ro
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - QUESTDB_METRICS_URL=${QUESTDB_METRICS_URL:-http://host.docker.internal:9003}
      - QUESTDB_HTTP_URL=${QUESTDB_HTTP_URL:-http://host.docker.internal:9000}
      - QUESTDB_HTTP_TOKEN=${QUESTDB_HTTP_TOKEN:-}
      - QUESTDB_SKIP_TLS_VERIFICATION=${QUESTDB_SKIP_TLS_VERIFICATION:-false}



