# Configuration for Telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "5s"
  omit_hostname = true
  precision = "1ms"
  flush_interval = "5s"

# -- INPUT PLUGINS ------------------------------------------------------ #
[[inputs.prometheus]]
  ## An array of urls to scrape metrics from.
  urls = ["${QUESTDB_METRICS_URL}"]
  url_tag=""
  metric_version = 2 # all entries will be on a single table
  ignore_timestamp = false


[[inputs.jolokia2_agent]]
  interval = "30s"
  name_prefix = "kafka_"
  tagexclude  = ["jolokia*"]

  # Add agents to query
  urls = ["http://broker:8778/jolokia","http://broker-2:8779/jolokia"]
  [inputs.jolokia2_agent.tags]
	system="kafka_jvm"

  [[inputs.jolokia2_agent.metric]]
    name  = "java_runtime"
    mbean = "java.lang:type=Runtime"
    paths = ["Uptime"]

[[inputs.jolokia2_agent.metric]]
    name     = "java_runtime"
    mbean    = "java.lang:name=*,type=GarbageCollector"
    paths    = ["name", "CollectionTime", "CollectionCount"]
    # tag_keys = ["name"]
    field_prefix = "$1"


  [[inputs.jolokia2_agent.metric]]
    name  = "java_runtime"
    mbean = "java.lang:type=Threading"
    paths = ["TotalStartedThreadCount", "ThreadCount", "DaemonThreadCount", "PeakThreadCount"]

  [[inputs.jolokia2_agent.metric]]
    name  = "java_runtime"
    mbean = "java.lang:type=ClassLoading"
    paths = ["LoadedClassCount", "UnloadedClassCount", "TotalLoadedClassCount"]


[[inputs.jolokia2_agent]]
  interval = "30s"
  name_prefix = "kafka_"
  tagexclude  = ["jolokia*"]
  fieldexclude   = [
     "*_EventType",
     "*_FifteenMinuteRate",
     "*_FiveMinuteRate",
     "*_MeanRate",
     "*_OneMinuteRate",
     "*_RateUnit",
     "*_LatencyUnit",
     "*_50thPercentile",
     "*_75thPercentile",
     "*_95thPercentile",
     "*_98thPercentile",
     "*_99thPercentile",
     "*_999thPercentile",
     "*_Min",
     "*_Mean",
     "*_Max",
     "*_StdDev"
   ]


  # Add agents to query
  urls = ["http://broker:8778/jolokia","http://broker-2:8779/jolokia"]
  [inputs.jolokia2_agent.tags]
	system="kafka_broker"

  [[inputs.jolokia2_agent.metric]]
    name         = "cluster"
    mbean        = "kafka.controller:name=*,type=*"
    field_prefix = "controller_$1_"

  [[inputs.jolokia2_agent.metric]]
    name         = "cluster"
    mbean        = "kafka.server:name=*,type=ReplicaManager"
    field_prefix = "replica_manager_$1_"

  [[inputs.jolokia2_agent.metric]]
    name     = "cluster"
    mbean    = "kafka.server:user=*,type=Request"
    field_prefix = "user_$1_"

  [[inputs.jolokia2_agent.metric]]
    name         = "cluster"
    mbean        = "kafka.network:name=*,request=*,type=RequestMetrics"
    field_prefix = "request_$1_"

  [[inputs.jolokia2_agent.metric]]
    name         = "cluster"
    mbean        = "kafka.server:name=*,type=BrokerTopicMetrics"
    field_prefix = "topics_$1_"

  [[inputs.jolokia2_agent.metric]]
    name         = "topic"
    mbean        = "kafka.server:name=*,topic=*,type=BrokerTopicMetrics"
    field_prefix = "$1_$2_"
    tag_keys     = ["topic"]

  [[inputs.jolokia2_agent.metric]]
    name       = "partition"
    mbean      = "kafka.log:name=*,partition=*,topic=*,type=Log"
    field_name = "$1_"
    tag_keys   = ["topic", "partition"]

  [[inputs.jolokia2_agent.metric]]
    name       = "partition"
    mbean      = "kafka.cluster:name=UnderReplicated,partition=*,topic=*,type=Partition"
    field_name = "UnderReplicatedPartitions"
    tag_keys   = ["topic", "partition"]


# -- AGGREGATOR PLUGINS ------------------------------------------------- #
# Merge metrics into multifield metrics by series key
[[aggregators.merge]]
  ## If true, the original metric will be dropped by the
  ## aggregator and will not get sent to the output plugins.
  drop_original = true

[[processors.regex]]
  namepass = ["*"]

  [[processors.regex.fields]]
    key = ".*"
    pattern = "-"
    replacement = "_"

  [[processors.regex.tags]]
    key = ".*"
    pattern = "-"
    replacement = "_"



# -- OUTPUT PLUGINS ----------------------------------------------------- #
[[outputs.influxdb_v2]]
  urls = ["${QUESTDB_HTTP_URL}"]
  token = "${QUESTDB_HTTP_TOKEN}"
  bucket = "questdb-metrics"
  content_encoding = "identity"  # Important to ensuring no gzip encoding
  # This is in case you are self-managing QuestDB under TLS with a self-signed certificate
  insecure_skip_verify = ${QUESTDB_SKIP_TLS_VERIFICATION}



